{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Brain Tumor MRI Segemtation using UNet\n",
    "\n",
    "This project uses a Convolutional Neural Network (CNN) to classify MRI brain scan images into multiple tumor types. The model is trained using the **BraTS2020** dataset pre organised and converted to .npy files from .nii files\n",
    "\n",
    "### Objective\n",
    "To segment MRI images of the brain into:\n",
    "- background\n",
    "- edema,\n",
    "- non-enhancing,\n",
    "- enhancing tumor\n",
    "\n",
    "We use **transfer learning with resnet18**\n",
    "\n",
    "We train a seperate model for each *modularity available (flair, t1, t1ce,t2)* and then ensemble them to make pridictions."
   ],
   "metadata": {
    "id": "ZCC1CCYrQhWc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os, random\n",
    "import torch\n",
    "from dataset import BraTSDataset2D\n",
    "from torch.utils.data import DataLoader\n",
    "import random"
   ],
   "metadata": {
    "id": "8IDApnbwHHJA",
    "ExecuteTime": {
     "end_time": "2025-08-16T14:46:48.243856Z",
     "start_time": "2025-08-16T14:46:44.239562Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ],
   "metadata": {
    "id": "ERPelcsjIIwG",
    "ExecuteTime": {
     "end_time": "2025-08-16T14:46:51.365886Z",
     "start_time": "2025-08-16T14:46:48.260534Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwcqVP-9ILLJ",
    "outputId": "0fae8860-13ac-401f-86e9-8fc6c80e8858",
    "ExecuteTime": {
     "end_time": "2025-08-16T14:46:52.248412Z",
     "start_time": "2025-08-16T14:46:52.079882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Pipeline\n",
    "\n",
    "- Dataset Class: BraTSDataset2D\n",
    "- Mode: Slice-wise 2D training\n",
    "- Preprocessing:\n",
    "  - Normalization per slice\n",
    "  - Label remapping (4 → 3)"
   ],
   "metadata": {
    "id": "CgP5qy0eN08v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def check_files(root_dir, modality):\n",
    "  mod_folder = os.path.join(root_dir, modality)\n",
    "  case_ids = [f.replace(\".npy\", \"\") for f in os.listdir(mod_folder)]\n",
    "\n",
    "  random.seed(42)\n",
    "  random.shuffle(case_ids)\n",
    "  split_idx = int(0.8 * len(case_ids))\n",
    "  train_ids = case_ids[:split_idx]\n",
    "  val_ids   = case_ids[split_idx:]\n",
    "\n",
    "  print(f\"{modality} - Training: {len(train_ids)}, Validation: {len(val_ids)}\")\n",
    "  return train_ids, val_ids"
   ],
   "metadata": {
    "id": "W2iouiKyH0v5",
    "ExecuteTime": {
     "end_time": "2025-08-16T14:47:06.298445Z",
     "start_time": "2025-08-16T14:47:06.291517Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "def make_dataloaders(root_dir, train_ids, val_ids, modality):\n",
    "\n",
    "  train_dataset = BraTSDataset2D(root_dir=root_dir, case_ids=train_ids, modality_name=modality)\n",
    "  val_dataset   = BraTSDataset2D(root_dir=root_dir, case_ids=val_ids, modality_name=modality)\n",
    "\n",
    "  train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "  val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "  print(\"DataLoaders ready!\")\n",
    "  return train_loader, val_loader"
   ],
   "metadata": {
    "id": "kQTtBqiDIE7R",
    "ExecuteTime": {
     "end_time": "2025-08-16T14:47:08.117750Z",
     "start_time": "2025-08-16T14:47:08.113510Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "- **Architecture**: U-Net (2D)\n",
    "- Input Channels: Single modality (e.g., flair)\n",
    "- Output: Pixel-wise segmentation (4 classes)\n",
    "\n",
    "- **Loss Function**: Dice Loss\n",
    "- **Optimizer**: AdamW\n",
    "- **Learning Rate Scheduler**:CosineAnnealingLR"
   ],
   "metadata": {
    "id": "KxubRtYLOGt8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "in_channels = 1\n",
    "classes = 4      # 0=background, 1=edema, 2=core, 3=enhancing\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=in_channels,\n",
    "    classes=classes\n",
    ").to(device)"
   ],
   "metadata": {
    "id": "DF4PsgRnINT5",
    "ExecuteTime": {
     "end_time": "2025-08-16T14:47:16.324925Z",
     "start_time": "2025-08-16T14:47:16.170810Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "loss_fn = smp.losses.DiceLoss(mode=\"multiclass\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)"
   ],
   "metadata": {
    "id": "n8lIxgRbIPVP",
    "ExecuteTime": {
     "end_time": "2025-08-16T14:47:17.607640Z",
     "start_time": "2025-08-16T14:47:17.603622Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def train_val_loop(model, train_loader, val_loader):\n",
    "  # -------------------------------\n",
    "  # Training loop\n",
    "  # -------------------------------\n",
    "  num_epochs = 10\n",
    "  metrics = []\n",
    "  for epoch in range(1, num_epochs+1):\n",
    "      model.train()\n",
    "      train_loss = 0.0\n",
    "      for imgs, masks in tqdm(train_loader, desc=f\"Epoch {epoch} [Train]\"):\n",
    "          imgs, masks = imgs.to(device), masks.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(imgs)\n",
    "          loss = loss_fn(outputs, masks)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          train_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "      scheduler.step()\n",
    "      train_loss /= len(train_loader.dataset)\n",
    "      print(f\"Epoch {epoch} - Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "      # -------------------------------\n",
    "      # Validation loop\n",
    "      # -------------------------------\n",
    "      model.eval()\n",
    "      val_loss = 0.0\n",
    "      with torch.no_grad():\n",
    "          for imgs, masks in tqdm(val_loader, desc=f\"Epoch {epoch} [Val]\"):\n",
    "              imgs, masks = imgs.to(device), masks.to(device)\n",
    "              outputs = model(imgs)\n",
    "              loss = loss_fn(outputs, masks)\n",
    "              val_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "      val_loss /= len(val_loader.dataset)\n",
    "      print(f\"Epoch {epoch} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "      metrics.append([train_loss, val_loss])\n",
    "  print(\"Training complete!\")\n",
    "\n",
    "  return model.state_dict(), metrics"
   ],
   "metadata": {
    "id": "URALUfpKIRZU",
    "ExecuteTime": {
     "end_time": "2025-08-16T14:47:19.117977Z",
     "start_time": "2025-08-16T14:47:19.111080Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## flair"
   ],
   "metadata": {
    "id": "047u1EcTNdhK"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T14:47:26.310712Z",
     "start_time": "2025-08-16T14:47:26.307609Z"
    }
   },
   "cell_type": "code",
   "source": "root_dir = \"../data/BraTS_2020_Train\"",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "train_ids , val_ids = check_files(root_dir = root_dir ,modality = \"flair\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9k9RO0VyL3Bm",
    "outputId": "a74ed0f2-218b-4b7b-9277-644c3c432bac",
    "ExecuteTime": {
     "end_time": "2025-08-16T14:47:27.492015Z",
     "start_time": "2025-08-16T14:47:27.483161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flair - Training: 295, Validation: 74\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "train_loader, val_loader = make_dataloaders(root_dir = root_dir, train_ids = train_ids, val_ids = val_ids, modality = \"flair\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7v0YcTd1MXGJ",
    "outputId": "412ef05d-d08a-4440-be16-1d59a4cbd9da",
    "ExecuteTime": {
     "end_time": "2025-08-16T14:47:57.959835Z",
     "start_time": "2025-08-16T14:47:45.307532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders ready!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "weights , metrics = train_val_loop(model, train_loader, val_loader)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "UjGZqgG7JtUT",
    "outputId": "b681a753-444f-4d54-a279-307559f9bac2"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1 [Train]:   2%|▏         | 50/2858 [03:17<3:04:41,  3.95s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-2611353947.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mweights\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_val_loop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_loader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipython-input-2142566407.py\u001B[0m in \u001B[0;36mtrain_val_loop\u001B[0;34m(model, train_loader, val_loader)\u001B[0m\n\u001B[1;32m      8\u001B[0m       \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m       \u001B[0mtrain_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m       \u001B[0;32mfor\u001B[0m \u001B[0mimgs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmasks\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdesc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34mf\"Epoch {epoch} [Train]\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m           \u001B[0mimgs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmasks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimgs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmasks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m           \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1179\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1180\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1181\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1182\u001B[0m                 \u001B[0;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1183\u001B[0m                 \u001B[0;31m# Update and possibly print the progressbar.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    706\u001B[0m                 \u001B[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    707\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 708\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    709\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    710\u001B[0m             if (\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1456\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1457\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_shutdown\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1458\u001B[0;31m             \u001B[0midx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1459\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1460\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1408\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1409\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory_thread\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_alive\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1410\u001B[0;31m                 \u001B[0msuccess\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_try_get_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1411\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0msuccess\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1412\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1249\u001B[0m         \u001B[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1250\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1251\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data_queue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1252\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1253\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.11/queue.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    178\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mremaining\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0.0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m                         \u001B[0;32mraise\u001B[0m \u001B[0mEmpty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnot_empty\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mremaining\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m             \u001B[0mitem\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnot_full\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.11/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    329\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    330\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 331\u001B[0;31m                     \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    332\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    333\u001B[0m                     \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(weights, f\"./flair_model.pth\")"
   ],
   "metadata": {
    "id": "ibfqbtBBNNyS"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
